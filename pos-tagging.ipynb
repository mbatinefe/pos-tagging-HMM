{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GON_gOpjqL6G"
      },
      "source": [
        "# **Part of Speech Tagging using Hidden Markov Models**\n",
        "\n",
        "\n",
        "My **OWN** Hidden Markov Model to predict part of speech tags of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "JF-ZzkgtK_Ju"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def clone_turkish_treebanks():\n",
        "  # We will Clone the Turkish treebanks repository from Google Research.\n",
        "  repo_url = \"https://github.com/google-research-datasets/turkish-treebanks.git\"\n",
        "  target_dir = \"turkish-treebanks\"\n",
        "  result = subprocess.run([\"git\", \"clone\", repo_url], capture_output=True, text=True)\n",
        "\n",
        "def move_conllu_file():\n",
        "  # We will copy the conllu files to /content directory.\n",
        "  # web.conllu is our Web domain text\n",
        "  # wiki.conllu is our Wikipedia domain text\n",
        "  source = \"turkish-treebanks/data/web.conllu\"\n",
        "  dest_dir = \"/content\"\n",
        "  dest_file = os.path.join(dest_dir, \"web.conllu\")\n",
        "  shutil.copy2(source, dest_file)\n",
        "  dest_file2 = os.path.join(dest_dir, \"wiki.conllu\")\n",
        "  shutil.copy2(source, dest_file2)\n",
        "\n",
        "# Run the functions\n",
        "if __name__ == \"__main__\":\n",
        "  clone_turkish_treebanks()\n",
        "  move_conllu_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9bOEe3N9mtci"
      },
      "outputs": [],
      "source": [
        "def read_conll(file_path):\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # Skip metadata lines starting with \"#\"\n",
        "            if line.startswith(\"#\"):\n",
        "                continue\n",
        "\n",
        "            # Sentence boundary (blank line)\n",
        "            if not line:\n",
        "                if sentence:\n",
        "                    sentences.append(sentence)\n",
        "                    sentence = []\n",
        "            else:\n",
        "                # Split the line into columns and extract word and POS tag\n",
        "                columns = line.split('\\t')\n",
        "                if len(columns) > 3:  # Check to ensure the line has expected columns\n",
        "                    word = columns[2]\n",
        "                    if word == '_':\n",
        "                      continue\n",
        "\n",
        "                    pos_tag = columns[3]\n",
        "                    sentence.append((word, pos_tag))\n",
        "\n",
        "        # Add the last sentence if the file doesn't end with a blank line\n",
        "        if sentence:\n",
        "            sentences.append(sentence)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# Usage\n",
        "web_file_path = \"/content/web.conllu\"\n",
        "wiki_file_path = \"/content/wiki.conllu\"\n",
        "\n",
        "web_sentences = read_conll(web_file_path)\n",
        "wiki_sentences = read_conll(wiki_file_path)\n",
        "\n",
        "sentences = web_sentences + wiki_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lma0qsepacW",
        "outputId": "d794fee8-30ff-4010-f9d5-928452392d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5082"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Es7c7EH7wg"
      },
      "source": [
        "## 1. Preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "evselvW7Bwbq"
      },
      "outputs": [],
      "source": [
        "def prepare_data(sentences, tag_list):\n",
        "\n",
        "  # Considering only the tags that are in the tag_list\n",
        "\n",
        "  # We will store filtered list of sentences that have valid tags\n",
        "  prepared_sentences = []\n",
        "  for sentence in sentences:\n",
        "    filtered_words = [] # We will store filtered words of a sentence\n",
        "    for (word, tag) in sentence: # Loop over words and tags\n",
        "      if tag in tag_list: # List of POS tags that we keep\n",
        "        filtered_words.append((word, tag)) # We add if the tag is in list\n",
        "    if filtered_words: # If the sentence is not empty\n",
        "      prepared_sentences.append(filtered_words) # We add the sentence to the list\n",
        "  return prepared_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfQqtk3IH57J"
      },
      "source": [
        "## 2. Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "YaC_RVVMxnCz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# This is for our data splitting\n",
        "# Initialize empty set to store unique tags\n",
        "unique_tags = set()\n",
        "\n",
        "# We loop through each sentence in corpus\n",
        "for sentence in sentences:\n",
        "  # Iterate through each word-tag pair in the sentence\n",
        "  for word, tag in sentence:\n",
        "    # Add each tag to the set -> we removed duplicates automatically\n",
        "    unique_tags.add(tag)\n",
        "\n",
        "# Convert set to sorted list\n",
        "all_tags = list(unique_tags)\n",
        "\n",
        "# We need two versions of the dataset\n",
        "# 1 ->> Full dataset with all POS tags\n",
        "full_sentences = prepare_data(sentences, all_tags)\n",
        "# 2 ->> Limited dataset with only asked POS tags from Professor\n",
        "limited_sentences = prepare_data(sentences, [\"ADJ\", \"ADV\", \"NOUN\", \"VERB\", \"PUNC\"])\n",
        "\n",
        "# Set random seed for all random operations\n",
        "random.seed(42)\n",
        "\n",
        "# Calculate split sizes ->>> 80% train and 20% test\n",
        "train_size_full = int(0.8 * len(full_sentences))\n",
        "train_size_limited = int(0.8 * len(limited_sentences))\n",
        "\n",
        "# Split full tagset data\n",
        "train_sentences_full = full_sentences[:train_size_full]\n",
        "test_sentences_full = full_sentences[train_size_full:]\n",
        "\n",
        "# Split limited tagset data\n",
        "train_sentences_limited = limited_sentences[:train_size_limited]\n",
        "test_sentences_limited = limited_sentences[train_size_limited:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5B05ac6IIM4"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "4gMEapoWq9GM"
      },
      "outputs": [],
      "source": [
        "def create_HMM(train_sentences):\n",
        "  '''\n",
        "    type train_sentences: list of tuples\n",
        "    param train_sentences: The list of tuples  (word, POS tag) for the training data sentences\n",
        "    rtype: dict\n",
        "    return: the transitions count dictionary between tags\n",
        "    rtype: dict\n",
        "    return: the emissions count dictionary for tags and words\n",
        "    rtype: dict\n",
        "    return: the tag count dictionary for the POS tags\n",
        "    rtype: set\n",
        "    return: the vocabulary of the corpus\n",
        "\n",
        "  '''\n",
        "\n",
        "  transitions = {} # We stores tag transition probabilities\n",
        "  emissions = {} # We stores word emission probabilities\n",
        "  tag_counts = {} # To Keep count of each tag\n",
        "  vocabulary = set() # Stores unique words\n",
        "  total_word_count = 0  # Total word count\n",
        "\n",
        "  # We go through each sentence\n",
        "  for sentence in train_sentences:\n",
        "    current_tag = \"<START>\" # Mark sentence beginning\n",
        "\n",
        "  # Iterate through each word-tag pair in the sentence\n",
        "    for current_word, next_tag in sentence:\n",
        "      # We track transition from current_tag to next_tag\n",
        "      if current_tag not in transitions:\n",
        "        transitions[current_tag] = {}\n",
        "      transitions[current_tag][next_tag] = transitions[current_tag].get(next_tag, 0) + 1\n",
        "\n",
        "      # We track emission of word from its tag\n",
        "      if next_tag not in emissions:\n",
        "        emissions[next_tag] = {}\n",
        "      emissions[next_tag][current_word] = emissions[next_tag].get(current_word, 0) + 1\n",
        "\n",
        "      # We update statistics\n",
        "      tag_counts[next_tag] = tag_counts.get(next_tag, 0) + 1\n",
        "      vocabulary.add(current_word)\n",
        "      total_word_count += 1\n",
        "\n",
        "      # We prepare for next iteration\n",
        "      current_tag = next_tag\n",
        "\n",
        "    # Mark sentence end here\n",
        "    if current_tag not in transitions:\n",
        "      transitions[current_tag] = {}\n",
        "    transitions[current_tag][\"<END>\"] = transitions[current_tag].get(\"<END>\", 0) + 1\n",
        "\n",
        "  return transitions, emissions, tag_counts, vocabulary, total_word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "eIjSk9Sh6kko"
      },
      "outputs": [],
      "source": [
        "transitions_full, emissions_full, tag_counts_full, vocab_full, word_count_full = create_HMM(train_sentences_full)\n",
        "transitions_limited, emissions_limited, tag_counts_limited, vocab_limited, word_count_limited = create_HMM(train_sentences_limited)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2kvRotSY4V5"
      },
      "source": [
        "## 4. POS tag prediction for test data\n",
        "\n",
        "Viterbi algorithm to predict the POS tags of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "xo1ORuDU7KwO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "def viterbi(test_sentence, transitions, emissions, tag_counts, word_count):\n",
        "    '''\n",
        "    type test_sentence: list of strings\n",
        "    param test_sentence: list of words in a sentence\n",
        "    type transitions: dict\n",
        "    param: the transitions count dictionary between tags\n",
        "    type emissions: dict\n",
        "    param: the emissions count dictionary for tags and words\n",
        "    type tag_counts: dict\n",
        "    param: the tag count dictionary for the POS tags\n",
        "    type word_count: int\n",
        "    param: the word count of the training corpus\n",
        "    rtype: list\n",
        "    return: the list of predicted tags for the test sentence\n",
        "\n",
        "    '''\n",
        "    #viterbi matrix for the test sentence. The matrix has +2 in each side since we add\n",
        "    #START and END tags for probability calculation.\n",
        "    v_matrix = np.empty(shape=(len(tag_counts)+2,len(sentences)+2))\n",
        "    v_matrix.fill(-1)\n",
        "    v_matrix[0][0] = 0\n",
        "\n",
        "    #fill up the viterbi matrix for each cell, starting with the first word.\n",
        "    # for every word, check each tag's probability of appearing here.\n",
        "    ## iterate over the tags:\n",
        "    ## calculate the best transition probability for the current tag from a previous tag (again iteration of all possible tags)\n",
        "    ## calculate the emission probability of word coming up from the current tag\n",
        "    ## sum them up to get to the best probability of P(tag|word).\n",
        "    ## keep the best path coming to that cell\n",
        "    #after filling up the viterbi matrix, follow the best path back to predict the tags from the final cell.\n",
        "    # in the end you are looking at len(tags)xlen(tags) possibilities for each word\n",
        "\n",
        "    tags = list(tag_counts.keys())  # We will get unique POS tags\n",
        "    backpointer = np.zeros((len(test_sentence), len(tags)), dtype=int)  # And will take track of best paths\n",
        "\n",
        "    # This is for Forward Pass -> We will calculate probabilities for each position\n",
        "    for t in range(len(test_sentence)):\n",
        "      word = test_sentence[t] # Get the word\n",
        "\n",
        "      # We check each possible current tag\n",
        "      for j, curr_tag in enumerate(tags):\n",
        "        # We try to find max_probability\n",
        "        max_prob = float('-inf')  # Track maximum probability\n",
        "        best_prev = 0  # Index of best previous tag\n",
        "\n",
        "        # Calculate emission probability P(word|tag) with smoothing\n",
        "        emit_p = math.log(emissions.get(curr_tag, {}).get(word, 1) / (tag_counts[curr_tag] + word_count))\n",
        "\n",
        "        # Find best previous tag\n",
        "        for i, prev_tag in enumerate(tags):\n",
        "          # Check first word (transition from START) compared to other positions\n",
        "          if t == 0:\n",
        "            trans_p = math.log(transitions.get(\"<START>\", {}).get(curr_tag, 1) / (tag_counts.get(\"<START>\", len(tags))))\n",
        "          else:\n",
        "            trans_p = math.log(transitions.get(prev_tag, {}).get(curr_tag, 1) / (tag_counts[prev_tag]))\n",
        "\n",
        "          # Calculate total path prob coming from transition and emission\n",
        "          curr_prob = v_matrix[i][t] + trans_p + emit_p\n",
        "\n",
        "          # We update if there exist better path\n",
        "          if curr_prob > max_prob:\n",
        "            max_prob = curr_prob\n",
        "            best_prev = i\n",
        "\n",
        "        # In the end, we store best prob and backpointer\n",
        "        v_matrix[j][t+1] = max_prob\n",
        "        backpointer[t][j] = best_prev\n",
        "\n",
        "    # BACKWARD PASS: We reconstruct the best tag sequence here\n",
        "    predicted_tags = []  # Store final sequence of predicted tags here\n",
        "\n",
        "    # Find the tag with highest prob in final position\n",
        "    # 1 is reserved for END tag\n",
        "    # We use -2 index\n",
        "    curr_best = np.argmax(v_matrix[:, -2])  # Index of maximum prob\n",
        "\n",
        "    # Backtrack through the sentence from right to left\n",
        "    for t in range(len(test_sentence)-1, -1, -1):\n",
        "        # Add current best tag to front of seq\n",
        "        predicted_tags.insert(0, tags[curr_best])\n",
        "        # Follow backpointer to previous best tag\n",
        "        curr_best = backpointer[t][curr_best]\n",
        "\n",
        "    return predicted_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec0gNpt6ZKJc"
      },
      "source": [
        "## 5. Evaluate the HMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDH-EQq1tk8p",
        "outputId": "433a0cad-6071-4c6c-a1e8-57144707ee6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------Results for full tag set--------------------------\n",
            "Accuracy: 0.7551\n",
            "F1 Macro: 0.5322\n",
            "F1 Weighted: 0.7549\n",
            "\n",
            "--------------------------Results for limited tag set--------------------------\n",
            "Accuracy: 0.8889\n",
            "F1 Macro: 0.7478\n",
            "F1 Weighted: 0.8792\n",
            "\n",
            "--------------------------Confusion Matrix (Full Tags)--------------------------\n",
            "\n",
            "Confusion Matrix:\n",
            "True\\Pred\t    PRON     PRT    VERB    CONJ   PUNCT    NOUN     ADJ     NUM     DET     ADP     ADV       X   AFFIX    ONOM\n",
            "PRON    \t     191       0      29       0       0      41       4       0      59       0       3       0       0       0\n",
            "PRT     \t       0     119      73      11       0      12       0       0       0       0       3       0       0       0\n",
            "VERB    \t      24       5    2014       0       6     219       8       0       7       4       1       0       0       0\n",
            "CONJ    \t       1       4       6     359       1      28       4       0       4      11       5       1       0       0\n",
            "PUNCT   \t     957       0       0       0     547       6       0       0       0       0       0       0       0       0\n",
            "NOUN    \t      26       0     173       0      35    3859      19       5       3       7       3       0       0       0\n",
            "ADJ     \t       0       0      27       1      13     216     134       0       0       0       8       0       0       0\n",
            "NUM     \t       1       0      11       0       7      94       0      50       8       0       0       0       0       0\n",
            "DET     \t       5       0      13       0       0       3       0       0     366       1      24       0       0       0\n",
            "ADP     \t       0       0      28       1       0     124       0       0       1     246       2       0       0       0\n",
            "ADV     \t       1       0      13       4       8      72      25       0       9       5     208       0       0       0\n",
            "X       \t      14       1      11       9      17      44       0       0       0       0       1      15       0       0\n",
            "AFFIX   \t       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            "ONOM    \t       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            "\n",
            "--------------------------Confusion Matrix (Limited Tags)--------------------------\n",
            "\n",
            "Confusion Matrix:\n",
            "True\\Pred\t    VERB    NOUN     ADJ     ADV\n",
            "VERB    \t    2114     166       7       1\n",
            "NOUN    \t     190    3926       9       5\n",
            "ADJ     \t      24     246     122       7\n",
            "ADV     \t      20      99      22     204\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# This function created to display the confusion matrix in a readable format.\n",
        "def print_confusion_matrix(conf_matrix, tags):\n",
        "  print(\"\\nConfusion Matrix:\")\n",
        "\n",
        "  print(\"True\\\\Pred\", end=\"\\t\") # Label for the true tags\n",
        "  for tag in tags:\n",
        "    print(f\"{tag:>8}\", end=\"\") # Print each predicted tag as column head\n",
        "  print()# Move to the next line after headers\n",
        "\n",
        "  # Print each row of the confusion matrix\n",
        "  for i, true_tag in enumerate(tags):\n",
        "    print(f\"{true_tag:8}\", end=\"\\t\") # Print the actual tag at the start of the row\n",
        "    for j in range(len(tags)):\n",
        "      print(f\"{conf_matrix[i][j]:8}\", end=\"\") # Print the count of predictions\n",
        "    print()\n",
        "\n",
        "\n",
        "# This function created to calculate f1 score\n",
        "def calculate_f1_score(tp, fp, fn):\n",
        "\n",
        "  # tp: True positives - correct predictions\n",
        "  # fp: False positives - incorrect predictions\n",
        "  # fn: False negatives - missed predictions\n",
        "\n",
        "  # If no true positives -> to prevent 0 / x issue\n",
        "  if tp == 0:\n",
        "    return 0.0\n",
        "\n",
        "  # Calculate precision\n",
        "  # If denominator is 0 -> return 0 to avoid division by zero\n",
        "  precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "  # Calculate recall\n",
        "  # If denominator is 0 -> return 0 to avoid division by zero\n",
        "  recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "  # Calculate F1 score: 2 * (precision * recall) / (precision + recall)\n",
        "  # If denominator is 0 -> return 0 to avoid division by zero\n",
        "  if precision + recall > 0:\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "  else:\n",
        "    f1 = 0.0\n",
        "\n",
        "  return f1\n",
        "\n",
        "def evaluate_models(test_sentences, transitions, emissions, tag_counts, word_count):\n",
        "    # test_sentences: List of sentences\n",
        "    # transitions: Transition probabilities between tags\n",
        "    # emissions: Emission probabilities of words given tags\n",
        "    # tag_counts: Count of how many times each tag appears in given data\n",
        "    # word_count: Total number of words in data\n",
        "\n",
        "    true_tags = []  # This is list to store all true tags from the test data\n",
        "    prediction_tags = []  # This is list to store all predicted tags by the model\n",
        "\n",
        "    # Loop through each sentence in the test data\n",
        "    for sentence in test_sentences:\n",
        "      # Here, we separate words and their true tags from the sentence\n",
        "      words = list(map(lambda x: x[0], sentence))\n",
        "      true = list(map(lambda x: x[1], sentence))\n",
        "\n",
        "      # We get the predictions from Viterbi\n",
        "      pred = viterbi(words, transitions, emissions, tag_counts, word_count)\n",
        "\n",
        "      # We add the true and predicted tags to their respective lists\n",
        "      true_tags.extend(true)\n",
        "      prediction_tags.extend(pred)\n",
        "\n",
        "    # Calculate the overall accuracy of the model\n",
        "    accuracy = accuracy_score(true_tags, prediction_tags)\n",
        "\n",
        "    # We prepare to build confusion matrix and calculate F1 scores here\n",
        "    tag_list = list(tag_counts.keys()) # Get a list of all possible tags\n",
        "    tag_count = len(tag_list)\n",
        "    confusion_matrix = []\n",
        "    for _ in range(tag_count):\n",
        "        row = [0] * tag_count\n",
        "        confusion_matrix.append(row)\n",
        "\n",
        "    tag_metrics = {}\n",
        "    for tag in tag_list: # Also, initialize metrics for each tag\n",
        "        tag_metrics[tag] = {'tp': 0, 'fp': 0, 'fn': 0}\n",
        "\n",
        "    # Fill the confusion matrix and update metrics for each tag\n",
        "    for t, p in zip(true_tags, prediction_tags):\n",
        "      i = tag_list.index(t)  # Find index of true tag\n",
        "      j = tag_list.index(p)  # Find index of predicted tag\n",
        "      confusion_matrix[i][j] += 1  # Increment count in confusion matrix\n",
        "\n",
        "      if t == p:\n",
        "        tag_metrics[t]['tp'] += 1  # True Positive\n",
        "      else:\n",
        "        tag_metrics[t]['fn'] += 1  # False Negative\n",
        "        tag_metrics[p]['fp'] += 1  # False Positive\n",
        "\n",
        "    # Calculate F1 scores for each tag\n",
        "    f1_scores = {}\n",
        "    for tag in tag_list:\n",
        "      tp = tag_metrics[tag]['tp']\n",
        "      fp = tag_metrics[tag]['fp']\n",
        "      fn = tag_metrics[tag]['fn']\n",
        "\n",
        "      if tp + fp > 0 and tp + fn > 0:\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f1_scores[tag] = 2 * (precision * recall) / (precision + recall)\n",
        "      else:\n",
        "        f1_scores[tag] = 0.0\n",
        "\n",
        "    # Calculate the macro average of F1 scores (simple average)\n",
        "    f1_macro = sum(f1_scores.values()) / len(f1_scores)\n",
        "\n",
        "    # Calculate the weighted average of F1 scores based on tag frequency\n",
        "    total_tags = len(true_tags)\n",
        "    weighted_f1 = 0\n",
        "    for tag in tag_list:\n",
        "      weighted_f1 += f1_scores[tag] * true_tags.count(tag)\n",
        "    weighted_f1 /= total_tags\n",
        "\n",
        "    # Return all the evaluation metrics\n",
        "    return accuracy, f1_macro, weighted_f1, confusion_matrix, tag_list\n",
        "\n",
        "\n",
        "# Evaluation code starts here\n",
        "print(\"--------------------------Results for full tag set--------------------------\")\n",
        "\n",
        "# Evaluate the model using the full set of tags\n",
        "acc_full, f1_macro_full, f1_weighted_full, conf_full, tags_full = evaluate_models(\n",
        "  test_sentences_full,\n",
        "  transitions_full,\n",
        "  emissions_full,\n",
        "  tag_counts_full,\n",
        "  word_count_full\n",
        ")\n",
        "\n",
        "# Print the accuracy and F1 scores for full tag set\n",
        "print(f\"Accuracy: {acc_full:.4f}\")\n",
        "print(f\"F1 Macro: {f1_macro_full:.4f}\")\n",
        "print(f\"F1 Weighted: {f1_weighted_full:.4f}\")\n",
        "\n",
        "print(\"\\n--------------------------Results for limited tag set--------------------------\")\n",
        "\n",
        "# Evaluate the model using a limited set of tags\n",
        "acc_limited, f1_macro_limited, f1_weighted_limited, conf_limited, tags_limited = evaluate_models(\n",
        "  test_sentences_limited,\n",
        "  transitions_limited,\n",
        "  emissions_limited,\n",
        "  tag_counts_limited,\n",
        "  word_count_limited\n",
        ")\n",
        "\n",
        "# Print the accuracy and F1 scores for limited tag set\n",
        "print(f\"Accuracy: {acc_limited:.4f}\")\n",
        "print(f\"F1 Macro: {f1_macro_limited:.4f}\")\n",
        "print(f\"F1 Weighted: {f1_weighted_limited:.4f}\")\n",
        "\n",
        "# Print the confusion matrix for full tag set\n",
        "print(\"\\n--------------------------Confusion Matrix (Full Tags)--------------------------\")\n",
        "print_confusion_matrix(conf_full, tags_full)\n",
        "\n",
        "# Print the confusion matrix for limited tag set\n",
        "print(\"\\n--------------------------Confusion Matrix (Limited Tags)--------------------------\")\n",
        "print_confusion_matrix(conf_limited, tags_limited)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i4DqJjzu_xk",
        "outputId": "d4a6cff8-fc1b-4471-fabc-7ac451b22ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------Results after Rare Word Replacement (Full Tags)--------------------------\n",
            "Accuracy: 0.7596\n",
            "F1 Macro: 0.5311\n",
            "F1 Weighted: 0.7583\n",
            "\n",
            "--------------------------Results after Rare Word Replacement (Limited Tags)--------------------------\n",
            "Accuracy: 0.8833\n",
            "F1 Macro: 0.7399\n",
            "F1 Weighted: 0.8732\n",
            "\n",
            "--------------------------Confusion Matrix (Full Tags after Rare Word Replacement)--------------------------\n",
            "\n",
            "Confusion Matrix:\n",
            "True\\Pred\t    PRON     PRT    VERB    CONJ   PUNCT    NOUN     ADJ     NUM     DET     ADP     ADV       X   AFFIX    ONOM\n",
            "PRON    \t     188       0      29       0       0      44       5       0      58       0       3       0       0       0\n",
            "PRT     \t       0     118      73      11       0      13       0       0       0       0       3       0       0       0\n",
            "VERB    \t      24       5    1916       0       1     323       7       0       7       4       1       0       0       0\n",
            "CONJ    \t       1       4       6     359       0      29       4       0       4      11       5       1       0       0\n",
            "PUNCT   \t     957       0       0       0     549       4       0       0       0       0       0       0       0       0\n",
            "NOUN    \t      26       0      48       0       0    4022      16       5       3       7       3       0       0       0\n",
            "ADJ     \t       0       0      22       1       6     239     123       0       0       0       8       0       0       0\n",
            "NUM     \t       1       0       5       0       3     104       0      50       8       0       0       0       0       0\n",
            "DET     \t       5       0      13       0       0       6       0       0     363       1      24       0       0       0\n",
            "ADP     \t       0       0      27       1       0     125       0       0       1     246       2       0       0       0\n",
            "ADV     \t       1       0      11       4       4      79      25       0       8       5     208       0       0       0\n",
            "X       \t      14       1       8      11      17      45       0       0       0       0       1      15       0       0\n",
            "AFFIX   \t       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            "ONOM    \t       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            "\n",
            "--------------------------Confusion Matrix (Limited Tags after Rare Word Replacement)--------------------------\n",
            "\n",
            "Confusion Matrix:\n",
            "True\\Pred\t    VERB    NOUN     ADJ     ADV\n",
            "VERB    \t    2076     205       6       1\n",
            "NOUN    \t     185    3931       9       5\n",
            "ADJ     \t      24     252     116       7\n",
            "ADV     \t      18     101      23     203\n"
          ]
        }
      ],
      "source": [
        "# Bonus Enhancements\n",
        "def replace_rare_words(sentences, min_freq=2):\n",
        "  word_freq = {}\n",
        "\n",
        "  # Count word frequencies\n",
        "  for sentence in sentences:\n",
        "    for word, _ in sentence:\n",
        "        word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "  # This part mostly same as prepare_data function.\n",
        "  modified_sentences = []\n",
        "  for sentence in sentences:\n",
        "      modified_sentence = []\n",
        "      for word, tag in sentence:\n",
        "          if word_freq[word] < min_freq: # If lower than our freq\n",
        "              modified_sentence.append((\"<UNK>\", tag)) # Replace with <unk> tag\n",
        "          else:\n",
        "              modified_sentence.append((word, tag)) # Unless, same tactic as prepare_data function\n",
        "      modified_sentences.append(modified_sentence)\n",
        "  return modified_sentences\n",
        "\n",
        "# We replace here the rare words in both training and test sets\n",
        "train_sentences_full = replace_rare_words(train_sentences_full, min_freq=2)\n",
        "train_sentences_limited = replace_rare_words(train_sentences_limited, min_freq=2)\n",
        "\n",
        "#  We replace here the rare words in the test sets based on the vocabulary of the training sets\n",
        "test_sentences_full = replace_rare_words(test_sentences_full, min_freq=2)\n",
        "test_sentences_limited = replace_rare_words(test_sentences_limited, min_freq=2)\n",
        "\n",
        "# Recalculate HMM\n",
        "transitions_full, emissions_full, tag_counts_full, vocab_full, word_count_full = create_HMM(train_sentences_full)\n",
        "transitions_limited, emissions_limited, tag_counts_limited, vocab_limited, word_count_limited = create_HMM(train_sentences_limited)\n",
        "\n",
        "# Evaluate the HMM\n",
        "print(\"--------------------------Results after Rare Word Replacement (Full Tags)--------------------------\")\n",
        "\n",
        "acc_full, f1_macro_full, f1_weighted_full, conf_full, tags_full = evaluate_models(\n",
        "    test_sentences_full,\n",
        "    transitions_full,\n",
        "    emissions_full,\n",
        "    tag_counts_full,\n",
        "    word_count_full\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {acc_full:.4f}\")\n",
        "print(f\"F1 Macro: {f1_macro_full:.4f}\")\n",
        "print(f\"F1 Weighted: {f1_weighted_full:.4f}\")\n",
        "\n",
        "print(\"\\n--------------------------Results after Rare Word Replacement (Limited Tags)--------------------------\")\n",
        "\n",
        "acc_limited, f1_macro_limited, f1_weighted_limited, conf_limited, tags_limited = evaluate_models(\n",
        "    test_sentences_limited,\n",
        "    transitions_limited,\n",
        "    emissions_limited,\n",
        "    tag_counts_limited,\n",
        "    word_count_limited\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {acc_limited:.4f}\")\n",
        "print(f\"F1 Macro: {f1_macro_limited:.4f}\")\n",
        "print(f\"F1 Weighted: {f1_weighted_limited:.4f}\")\n",
        "\n",
        "print(\"\\n--------------------------Confusion Matrix (Full Tags after Rare Word Replacement)--------------------------\")\n",
        "print_confusion_matrix(conf_full, tags_full)\n",
        "\n",
        "print(\"\\n--------------------------Confusion Matrix (Limited Tags after Rare Word Replacement)--------------------------\")\n",
        "print_confusion_matrix(conf_limited, tags_limited)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
